{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alzheimer's Disease Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeo's part about what is AD and the sort of tests that are possible to detect it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Model Longitudinal Data in Medical Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges of Longitudinal Data\n",
    "\n",
    "Many medical studies are structured around the collection of longitudinal data, in which observations are made repeatedly from the same set of patients over the course of a series of study visits, often spanning months or years. This type of experimental design allows researchers to observe the progression of a disease in a patient, affording them a much more holistic understanding of the phenomena underlying the condition. Additionally, having multiple repeated measurements from the same patients allow for a better understanding of intersubject variability, fascilitating a more robust distinction between random measurement noise and true differences between patients.\n",
    "\n",
    "While longitudinal studies provide many key advantages over other experimental designs, they also a yield number of statistical complications that must be addressed. One of the foremost challenges is how to actually structure the longitudinal data in an appropriate way before beginning any form of analysis. All of the visits from a particular patient cannot be treated as independent of each other, since they originated from the same source, and thus, all the records from a single source must be combined [1]. A simple approach would be to treat each observation of a certain quantity (e.g. choleserol levels) as separate predictors, so a patient would have a value for their cholesteral at the first visit, one at their second visit, etc. The issue here, however, is that these predictors will be highly correlated with each other, presenting numerical difficulties for most standard statistical techniques [2]. Thus, efforts must be taken to account for this complication.\n",
    "\n",
    "Another issue that arrises with longitudinal study is missing data. Often, patients will drop out of a study mid-way through. For example, if a terminal disease is being studied, some patients may die during the course of the study, or may become too severely incapacitated to continue attending study visits [2]. The data from these patients should not simply be discarded, since they likely represent the most high-risk population that could benefit the most from the study's results. Additionally, sometimes the experimental design for a study may be altered mid-way through (such as adding a new test metric that was not recorded for the first participants) [1]. This results in all the early participants having missing data, since they do not have the new metric.\n",
    "\n",
    "One final complication of longitudinal studies is the existance of feedback processes in which the observations made during a patient's visits may influence the types of interventions they receive from their caregivers. This drastically alters many of the standard independence assumptions made in traditional analyses [1]. This type of complicating factor is somewhat beyond the scope of this project. That said, a the ADNI dataset being used does present many of the other standard challenges of longitudinal data—including correlated predictor values and missing data—so techniques were explored to handle both of these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation of measurements\n",
    "\n",
    "_Derived Variable Analysis:_\n",
    "\n",
    "One common approach used to avoid the issue of correlated measurements across patient visits is to generate new features that collapse the longitudinal aspect of the data into a single metric. There are a number of common choices for this mapping, such as taking the mean of the measurements or using the average rate of change [1]. In essense, this very common technique is a form of feature engineering, in which one seeks to capture much of the longitudinal information from the original measurements without introducing predictor colinearity. Depending on the mapping that is used to generate the derived variable, missing data can sometimes prove to be a problem, since some mappings may only function properly when all data is present [1]. Thus, the types of missingness in a dataset must be examined before choosing a set of derived variables.\n",
    "\n",
    "_Regression Methods:_\n",
    "\n",
    "As subset of derived variable analsysis, regression methods seek to fit a regression to the longitudinal response of each individual patient (see figure below as an example) and then use the parameters of these regressions as predictors/responses in the overall analysis [3]. This technique allows for highly interpretable derived variables that can be directly related to the longitudinal response of a particular patient. One variant of a regression method was applied to the ADNI dataset as part of our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"RegressionMethodsExample.png\" width=\"500\">\n",
    "<p style=\"margin-left:20em;margin-right:20em;\"> Example of a regression method, in which linear models are fit to each individual patient's longitudinal response. Figure duplicated from [1].</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data\n",
    "\n",
    "Before attempting to deal with missing data, it is important to understand whether observations are Missing Completely at Random (MCAR), Missing at Random (MAR), or Missing not at Random (MNAR) [2]. If the missingness is completely randomly distributed, then there would be no way _a priori_ to predict which data would be missing. In this case, most statistical estimates would be unbiased. That said, if data were missing due to some underlying phenomena (that is either captured in the data or not), this interaction could skew statistical results. For example, sometimes patients may choose to not return for all the visits of a study if their condition is not severe, and they therefore do not feel they need additional care. This would bias results, since only the more severe patients would be represented in the later subject visits. \n",
    "\n",
    "While it is not possible to determine whether there may be external factors contributing to the missingness that were not recorded as part of the study (i.e. MNAR), one must at least check that there are not trends within the dataset that can serve to predict the missingness trends for a particular patient. In subsequent sections, we will examine the types of missingness present in the ADNI dataset.\n",
    "\n",
    "Assuming that the missingness is relatively random among the patients, there are a number of different techniques for handling the missing values. As discussed in lecture, there are many different imputation schemes that attempt to fill in the missing values based on general statistics of the population (such as mean-imputation and median-imputation). These methods often do not bias overall predictions of a model, though they do skew the distribution and statistics for the resulting model parameters obtained from fitting. \n",
    "\n",
    "Another technique—which is utilized in our subsequent analysis—is to use derived variable analysis approaches to \"flatten\" the longitudinal aspect of the data and then weight the importance of participants based on the number of study visits they completed so as to create an unbiased model [1]. If a given patient is missing a substantial number of study visits, their information will be weighted less in the overall model training. This allows researchers to still use the patient's data without biasing their overall results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] P. Diggle, P. Heagerty, K.-Y. Liang, and S. L. Zeger, Analysis of Longitudinal Data, Oxford University Press, 2013.\n",
    "\n",
    "[2] T. P. Garcia and K. Marder, “Statistical Approaches to Longitudinal Data Analysis in Neurodegenerative Diseases: Huntington’s Disease as a Model,” Curr. Neurol. Neurosci. Rep., vol. 17, no. 2, 2017.\n",
    "\n",
    "[3] G. M. Fitzmaurice and C. Ravichandran, “A Primer in Longitudinal Data Analysis,” Circulation, vol. 118, no. 19, Nov. 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
